{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating Spam Filter using multinomial Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main goal of this project is to create a model, that based on near 6000 classified messages as SPAM or nonSPAM (labeled as HAM), it will distinguish if new message is SPAM or not. In this project I will be using multinomial Naive Bayes algorithm with some introduction to conditional probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "messages.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check what is percentages of SPAM and HAM messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radnomize messages first\n",
    "messagess_randomized = messages.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test set - 80% as training set, 20% as a test set\n",
    "train_len = round(len(messagess_randomized) * 0.8)\n",
    "train_msg = messagess_randomized[:train_len].copy().reset_index(drop=True)\n",
    "test_msg = messagess_randomized[train_len:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if train set has similar percentages of SPAM and HAM messages.\n",
    "train_msg[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if test set has similar percentages of SPAM and HAM messages.\n",
    "test_msg[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Later i guess  I needa do mcat study too \n",
       "1               But i haf enuff space got like 4 mb   \n",
       "2    Had your mobile 10 mths  Update to latest Oran...\n",
       "3    All sounds good  Fingers   Makes it difficult ...\n",
       "4    All done  all handed in  Don t know if mega sh...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all non-word characters by whitespace - only words are welcome here\n",
    "test_msg['SMS'] = test_msg['SMS'].str.replace('\\W', ' ')\n",
    "test_msg['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Yep  by the pretty sculpture\n",
       "1        Yes  princess  Are you going to make me moan \n",
       "2                           Welp apparently he retired\n",
       "3                                              Havent \n",
       "4    I forgot 2 ask ü all smth   There s a card on ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all non-word characters by whitespace - only words are welcome here\n",
    "train_msg['SMS'] = train_msg['SMS'].str.replace('\\W', ' ')\n",
    "train_msg['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting strings to lowercase\n",
    "test_msg['SMS'] = test_msg['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting strings to lowercase\n",
    "train_msg['SMS'] = train_msg['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets split all words in train text messages to list of words\n",
    "train_msg['SMS'] = train_msg['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [yep, by, the, pretty, sculpture]\n",
       "1    [yes, princess, are, you, going, to, make, me,...\n",
       "2                      [welp, apparently, he, retired]\n",
       "3                                             [havent]\n",
       "4    [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_msg['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some theory behind multinomial Naive Bayes algorithm (with help dataquest.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bayes Theorem its possible to calculate probability that new message is a spam: <br>\n",
    "<br>\n",
    "$$ P(SPAM|new\\;message)\\;=\\; \\frac{P(SPAM) \\cdot P(new\\;message|SPAM)}{P(new\\;message)} $$\n",
    "$$ P(HAM|new\\;message)\\;=\\; \\frac{P(HAM) \\cdot P(new\\;message|HAM)}{P(new\\;message)}  $$\n",
    "\n",
    "Since I need to only compare the values, it is possible to ignore division:<br>\n",
    "<br>\n",
    "$$ P(SPAM|new\\;message)\\;\\displaystyle \\propto\\; P(SPAM) \\cdot P(new\\;message|SPAM)$$\n",
    "$$ P(HAM|new\\;message)\\;\\displaystyle \\propto\\; P(HAM) \\cdot P(new\\;message|HAM) $$\n",
    "\n",
    "Given simple table:\n",
    "\n",
    "| LABEL | SMS                                            |\n",
    "|-------|------------------------------------------------|\n",
    "|   ?   | Secret code to unlock gift                     |\n",
    "\n",
    "<br>\n",
    "It is possible to calculate: <br>\n",
    "<br>\n",
    "$$ P(SPAM|\"Secret\\;code\\;to\\;unlockgift\")\\displaystyle \\propto P(SPAM) \\cdot P(\"Secret\\;code\\;to\\;unlock\\;gift\"|SPAM) $$\n",
    "$$ P(HAM|\"Secret\\;code\\;to\\;unlock\\;gift\")\\;\\displaystyle \\propto\\;P(HAM) \\cdot P(\"Secret\\;code\\;to\\;unlock\\;gift\"|HAM) $$\n",
    "Also\n",
    "$$ P(SPAM|w1,...,w5) = \\frac{P(SPAM\\cap(w1\\;\\cap...\\cap\\; w5)}{P(w1\\;\\cap\\;...\\;\\cap\\; w5)}$$\n",
    "$$ P(SPAM|w1,...,w5)\\;\\displaystyle \\propto\\;P(SPAM\\cap(w1\\;\\cap...\\cap\\; w5))$$\n",
    "\n",
    "And here it is, Naive Bayes algorithm assumes that words (w1,w2,w3,w4,w5) are conditional independent. Which is not true, i.e. word \"free\" will occur more frequent with words like \"prize\" or \"gift\". Thus ignoring conditional dependece is called 'naive' in this situation. Simplifying above equation:\n",
    "\n",
    "$$ P(SPAM|w1,...,w5)\\;\\displaystyle \\propto\\;P(SPAM)\\cdot P(w1|SPAM)\\;\\cdot\\;...\\;\\cdot\\; P(w5|SPAM)$$\n",
    "$$ P(HAM|w1,...,w5)\\;\\displaystyle \\propto\\;P(HAM)\\cdot P(w1|HAM)\\;\\cdot\\;...\\;\\cdot\\; P(w5|HAM)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given below data set:\n",
    "\n",
    "| LABEL | SMS                                                  |\n",
    "|-------|------------------------------------------------------|\n",
    "| SPAM  | WINNER!! You won a Secret gift!                      |\n",
    "|  HAM  | Hey hun, please buy groceries when you get back      |\n",
    "| SPAM  | Free prize! Just text us back with 12123 code.       |\n",
    "|   ?   | Secret code to unlock gift                           |\n",
    "\n",
    "I get probabilitities:\n",
    "$$ N_{SPAM} = 15 $$\n",
    "$$ N_{HAM} = 9 $$\n",
    "$$ N_{VOCABULARY} = N_{SPAM} + N_{HAM} = 24 $$\n",
    "$$ \\alpha = 1 <--- additive\\;smoothing $$\n",
    "NOTE: for more info about additive smoothing check out https://en.wikipedia.org/wiki/Additive_smoothing\n",
    "___________________________________________________________________________\n",
    "\n",
    "$$ P(SPAM) = \\frac{2}{3} $$\n",
    "$$ P(\"Secret\"|SPAM) = \\frac{N_{\"Secret\"|SPAM} + \\alpha}{N_{SPAM} + N_{VOCABULARY}} = \\frac{1 + 1}{15 + 24} = \\frac{2}{39}$$\n",
    "$$ P(\"code\"|SPAM) = \\frac{2}{39}$$\n",
    "$$ P(\"to\"|SPAM) = \\frac{1}{39}$$\n",
    "$$ P(\"unlock\"|SPAM) = \\frac{1}{39}$$\n",
    "$$ P(\"gift\"|SPAM) = \\frac{2}{39}$$\n",
    "$$ P(SPAM|\"Secret\\;code\\;to\\;unlockgift\")\\displaystyle \\propto \\frac{2}{3} \\cdot \\frac{2}{39} \\cdot \\frac{2}{39} \\cdot \\frac{1}{39} \\cdot \\frac{1}{39} \\cdot \\frac{2}{39} = \\frac{16}{270672597} = 5,9e-8$$\n",
    "\n",
    "___________________________________________________________________________\n",
    "$$ P(HAM) = \\frac{1}{3} $$\n",
    "$$ P(\"Secret\"|HAM) = \\frac{N_{\"Secret\"|SPAM} + \\alpha}{N_{HAM} + N_{VOCABULARY}} = \\frac{0 + 1}{9 + 24} = \\frac{1}{33}$$\n",
    "$$ P(\"code\"|HAM) = \\frac{1}{33}$$\n",
    "$$ P(\"to\"|HAM) = \\frac{1}{33}$$\n",
    "$$ P(\"unlock\"|HAM) = \\frac{1}{33}$$\n",
    "$$ P(\"gift\"|HAM) = \\frac{1}{33}$$\n",
    "$$ P(HAM|\"Secret\\;code\\;to\\;unlockgift\")\\displaystyle \\propto \\frac{1}{3} \\cdot \\frac{1}{33} \\cdot \\frac{1}{33} \\cdot \\frac{1}{33} \\cdot \\frac{1}{33} \\cdot \\frac{1}{33} = \\frac{1}{39135393} = 2,56e-8$$\n",
    "___________________________________________________________________________\n",
    "Now I can conclude that message is a SPAM\n",
    "$$ P(SPAM|\"Secret\\;code\\;to\\;unlockgift\") > P(HAM|\"Secret\\;code\\;to\\;unlockgift\") $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for multinomial Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented algorithm I will apply to my model. First lets extract vocabulary from all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sms in train_msg['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary that counts occurence of SMS words in vocabulary\n",
    "word_counts_per_sms = {unique_word : [0] * len(train_msg['SMS']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sms in enumerate(train_msg['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invited</th>\n",
       "      <th>kidding</th>\n",
       "      <th>145</th>\n",
       "      <th>700</th>\n",
       "      <th>messenger</th>\n",
       "      <th>mths</th>\n",
       "      <th>stays</th>\n",
       "      <th>txt</th>\n",
       "      <th>complain</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>honi</th>\n",
       "      <th>constantly</th>\n",
       "      <th>6zf</th>\n",
       "      <th>celeb</th>\n",
       "      <th>fancies</th>\n",
       "      <th>arm</th>\n",
       "      <th>mtmsg18</th>\n",
       "      <th>fo</th>\n",
       "      <th>jog</th>\n",
       "      <th>83600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   invited  kidding  145  700  messenger  mths  stays  txt  complain  \\\n",
       "0        0        0    0    0          0     0      0    0         0   \n",
       "1        0        0    0    0          0     0      0    0         0   \n",
       "2        0        0    0    0          0     0      0    0         0   \n",
       "3        0        0    0    0          0     0      0    0         0   \n",
       "4        0        0    0    0          0     0      0    0         0   \n",
       "\n",
       "   accounts  ...  honi  constantly  6zf  celeb  fancies  arm  mtmsg18  fo  \\\n",
       "0         0  ...     0           0    0      0        0    0        0   0   \n",
       "1         0  ...     0           0    0      0        0    0        0   0   \n",
       "2         0  ...     0           0    0      0        0    0        0   0   \n",
       "3         0  ...     0           0    0      0        0    0        0   0   \n",
       "4         0  ...     0           0    0      0        0    0        0   0   \n",
       "\n",
       "   jog  83600  \n",
       "0    0      0  \n",
       "1    0      0  \n",
       "2    0      0  \n",
       "3    0      0  \n",
       "4    0      0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate word counts data frame to training set\n",
    "clean_train_msg = pd.concat([train_msg, word_counts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>invited</th>\n",
       "      <th>kidding</th>\n",
       "      <th>145</th>\n",
       "      <th>700</th>\n",
       "      <th>messenger</th>\n",
       "      <th>mths</th>\n",
       "      <th>stays</th>\n",
       "      <th>txt</th>\n",
       "      <th>...</th>\n",
       "      <th>honi</th>\n",
       "      <th>constantly</th>\n",
       "      <th>6zf</th>\n",
       "      <th>celeb</th>\n",
       "      <th>fancies</th>\n",
       "      <th>arm</th>\n",
       "      <th>mtmsg18</th>\n",
       "      <th>fo</th>\n",
       "      <th>jog</th>\n",
       "      <th>83600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  invited  kidding  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0        0   \n",
       "2   ham                    [welp, apparently, he, retired]        0        0   \n",
       "3   ham                                           [havent]        0        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0        0   \n",
       "\n",
       "   145  700  messenger  mths  stays  txt  ...  honi  constantly  6zf  celeb  \\\n",
       "0    0    0          0     0      0    0  ...     0           0    0      0   \n",
       "1    0    0          0     0      0    0  ...     0           0    0      0   \n",
       "2    0    0          0     0      0    0  ...     0           0    0      0   \n",
       "3    0    0          0     0      0    0  ...     0           0    0      0   \n",
       "4    0    0          0     0      0    0  ...     0           0    0      0   \n",
       "\n",
       "   fancies  arm  mtmsg18  fo  jog  83600  \n",
       "0        0    0        0   0    0      0  \n",
       "1        0    0        0   0    0      0  \n",
       "2        0    0        0   0    0      0  \n",
       "3        0    0        0   0    0      0  \n",
       "4        0    0        0   0    0      0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SPAM) = 0.13458950201884254\n"
     ]
    }
   ],
   "source": [
    "p_spam = clean_train_msg['Label'].value_counts(normalize=True)['spam']\n",
    "print('P(SPAM) = {}'.format(p_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(HAM) = 0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "p_ham = clean_train_msg['Label'].value_counts(normalize=True)['ham']\n",
    "print('P(HAM) = {}'.format(p_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SPAM = 15190\n"
     ]
    }
   ],
   "source": [
    "n_spam_words = clean_train_msg[clean_train_msg['Label'] == 'spam']['SMS'].apply(len).sum()\n",
    "print('N_SPAM = {}'.format(n_spam_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_HAM = 57237\n"
     ]
    }
   ],
   "source": [
    "n_ham_words = clean_train_msg[clean_train_msg['Label'] == 'ham']['SMS'].apply(len).sum()\n",
    "print('N_HAM = {}'.format(n_ham_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_VOCABULARY = 7783\n"
     ]
    }
   ],
   "source": [
    "n_vocabulary = len(vocabulary)\n",
    "print('N_VOCABULARY = {}'.format(n_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary of P(w|SPAM) and dictionary P(w|HAM)\n",
    "p_word_given_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "p_word_given_ham = {unique_word: 0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_set_spam = clean_train_msg[clean_train_msg['Label'] == 'spam']\n",
    "clean_train_set_ham = clean_train_msg[clean_train_msg['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize N_word|SPAM and N_word|HAM\n",
    "n_word_given_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "n_word_given_ham = {unique_word: 0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count N_word|SPAM and N_word|HAM\n",
    "for unique_word in vocabulary:\n",
    "    n_word_given_spam[unique_word] = clean_train_set_spam[unique_word].sum()\n",
    "    n_word_given_ham[unique_word] = clean_train_set_ham[unique_word].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count P(w|SPAM) and P(w|HAM)\n",
    "for unique_word in vocabulary:\n",
    "    p_word_given_spam[unique_word] = (n_word_given_spam[unique_word] + alpha)/(n_spam_words + alpha*n_vocabulary)\n",
    "    p_word_given_ham[unique_word] = (n_word_given_ham[unique_word] + alpha)/(n_ham_words + alpha*n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All needed probablilities were calculated. Now lets create function that classifies messages to SPAM or HAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    # clean message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    '''    \n",
    "    This is where we calculate:\n",
    "\n",
    "    p_spam_given_message = ?\n",
    "    p_ham_given_message = ?\n",
    "    '''    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "\n",
    "    #print('P(Spam|message):', p_spam_given_message)\n",
    "    #print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'This message needs human judgement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_msg['predicted'] = test_msg['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess  i needa do mcat study too</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths  update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good  fingers   makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all done  all handed in  don t know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          later i guess  i needa do mcat study too        ham\n",
       "1   ham             but i haf enuff space got like 4 mb          ham\n",
       "2  spam  had your mobile 10 mths  update to latest oran...      spam\n",
       "3   ham  all sounds good  fingers   makes it difficult ...       ham\n",
       "4   ham  all done  all handed in  don t know if mega sh...       ham"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = 0\n",
    "total = len(test_msg['SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_msg.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct_prediction += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction: 1100\n",
      "Incorrect prediction: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "print('Correct prediction:', correct_prediction)\n",
    "print('Incorrect prediction:', total - correct_prediction)\n",
    "print('Accuracy:', correct_prediction/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that on 1114 messages, model failed to classify 14 messages, which gives 98,74% accuracy. Now, lets check out messages that was incorrecty classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "not heard from u4 a while  call me now am here all night with just my knickers on  make me beg for it like u did last time 01223585236 xx luv nikiyu4 net\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "more people are dogging in your area now  call 09090204448 and join like minded guys  why not arrange 1 yourself  there s 1 this evening  a 1 50 minapn ls278bb\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: spam\n",
      "unlimited texts  limited minutes \n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: spam\n",
      "26th of july\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: spam\n",
      "nokia phone is lovly  \n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: This message needs human judgement\n",
      "a boy loved a gal  he propsd bt she didnt mind  he gv lv lttrs  bt her frnds threw thm  again d boy decided 2 aproach d gal   dt time a truck was speeding towards d gal  wn it was about 2 hit d girl d boy ran like hell n saved her  she asked  hw cn u run so fast   d boy replied  boost is d secret of my energy  n instantly d girl shouted  our energy  n thy lived happily 2gthr drinking boost evrydy moral of d story   i hv free msgs d    gud ni8\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: spam\n",
      "no calls  messages  missed calls\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: ham, Message label predicted: spam\n",
      "we have sent jd for customer service cum accounts executive to ur mail id  for details contact us\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "oh my god  i ve found your number again  i m so glad  text me back xafter this msgs cst std ntwk chg  1 50\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "hi babe its chloe  how r u  i was smashed on saturday night  it was great  how was your weekend  u been missing me  sp visionsms com text stop to stop 150p text\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "0a networks allow companies to bill for sms  so they are responsible for their  suppliers   just as a shop has to give a guarantee on what they sell  b  g \n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "rct  thnq adrian for u text  rgds vatian\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "2 2 146tf150p\n",
      "\n",
      "\n",
      "___________________________________________________\n",
      "Message labeled: spam, Message label predicted: ham\n",
      "hello  we need some posh birds and chaps to user trial prods for champneys  can i put you down  i need your address and dob asap  ta r\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in test_msg.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] != row['predicted']:\n",
    "        print('___________________________________________________')\n",
    "        print('Message labeled: {}, Message label predicted: {}'.format(row['Label'], row['predicted']))\n",
    "        print(row['SMS'])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably model had some problem with SMS that has unique words like \"ni8\", \"ta\". Also in those messages were one letters 'r', 'u', 't'. Alone Letter like 't'  was caused by replacing \"'\" with space i.e don\"t -> don t. For better results I could get rid of those letters, and words like \"and\", \"or\", \"dont\", because those words has less information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
